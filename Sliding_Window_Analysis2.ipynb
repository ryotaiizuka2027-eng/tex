{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import re\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "# import shutil # ダミーデータ生成時のみ使用\n",
        "\n",
        "# ==========================================\n",
        "# 1. ダミーデータ生成パート (学習部分想定)\n",
        "# ※ ユーザーの環境では既にモデルがあるため、この部分は不要ですが\n",
        "#    動作確認用にコードのみ残してコメントアウト状態で置いておきます。\n",
        "# ==========================================\n",
        "# class MockStatsModel:\n",
        "#     \"\"\"statsmodelsの結果を模倣したダミークラス\"\"\"\n",
        "#     def __init__(self, variables):\n",
        "#         # 係数 (beta/weight)\n",
        "#         self.params = pd.Series(np.random.randn(len(variables)), index=variables)\n",
        "#         # 分散共分散行列の対角成分（分散）を模倣 (標準誤差 bse の2乗想定)\n",
        "#         self.bse = pd.Series(np.abs(np.random.randn(len(variables)) * 0.1), index=variables)\n",
        "#\n",
        "# def generate_mock_data(folder_path=\"models_folder\"):\n",
        "#     \"\"\"テスト用のpickleファイルを生成する（学習プロセスの代わり）\"\"\"\n",
        "#     if os.path.exists(folder_path):\n",
        "#         shutil.rmtree(folder_path)\n",
        "#     os.makedirs(folder_path)\n",
        "#\n",
        "#     base_vars = [\"const\", \"GDP\", \"CPI\"]\n",
        "#     extra_vars = [\"Unemployment\", \"InterestRate\", \"ExchangeRate\"]\n",
        "#\n",
        "#     # 2020年1月から月次でスライディングウィンドウしたと仮定\n",
        "#     start_date = datetime(2020, 1, 1)\n",
        "#\n",
        "#     print(f\"--- Generating mock data in '{folder_path}' ---\")\n",
        "#     for i in range(12):\n",
        "#         # 期間が進むにつれて変数が変わるシチュエーション\n",
        "#         current_vars = base_vars.copy()\n",
        "#         if i > 2: current_vars.append(extra_vars[0])\n",
        "#         if i > 5: current_vars.append(extra_vars[1])\n",
        "#         if i > 8: current_vars.remove(\"GDP\") # 変数が減るパターン\n",
        "#\n",
        "#         model = MockStatsModel(current_vars)\n",
        "#\n",
        "#         # ファイル名形式: exp1_ver1_YYYYMMDD.pkl\n",
        "#         date_str = (start_date + pd.DateOffset(months=i)).strftime('%Y%m%d')\n",
        "#         filename = f\"exp1_ver1_{date_str}.pkl\"\n",
        "#\n",
        "#         with open(os.path.join(folder_path, filename), 'wb') as f:\n",
        "#             pickle.dump(model, f)\n",
        "#\n",
        "#     print(\"Generation complete.\\n\")\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# 2. メイン処理: モデル読み込みとデータフレーム化\n",
        "# ==========================================\n",
        "\n",
        "def extract_date_from_filename(filename):\n",
        "    \"\"\"\n",
        "    ファイル名から日付らしき数字を抽出してソート用に返す関数\n",
        "    例: 'exp1_ver1_201101.pkl' -> '201101'\n",
        "    \"\"\"\n",
        "    # ファイル名から6桁～8桁の連続する数字を探す (YYMMDD, YYYYMMDDなど)\n",
        "    match = re.search(r'(\\d{6,8})', filename)\n",
        "    if match:\n",
        "        return match.group(1)\n",
        "    else:\n",
        "        # 数字が見つからない場合はファイル名そのまま\n",
        "        return filename\n",
        "\n",
        "def load_and_process_models(folder_path):\n",
        "    \"\"\"\n",
        "    指定フォルダ内の全pklファイルを日付順に読み込み、\n",
        "    係数と分散を抽出してDataFrameにする\n",
        "    \"\"\"\n",
        "    # pklファイルを取得\n",
        "    files = glob.glob(os.path.join(folder_path, \"*.pkl\"))\n",
        "\n",
        "    if not files:\n",
        "        print(f\"Error: No .pkl files found in {folder_path}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # ファイル名に含まれる日付数字でソートする\n",
        "    # これにより exp1_ver1_201101, exp1_ver1_201102... の順序を保証\n",
        "    files.sort(key=lambda x: extract_date_from_filename(os.path.basename(x)))\n",
        "\n",
        "    all_records = []\n",
        "    print(f\"Found {len(files)} models. Starting extraction...\")\n",
        "\n",
        "    for file_path in files:\n",
        "        filename = os.path.basename(file_path)\n",
        "\n",
        "        # 識別子として日付部分を取得、なければファイル名全体\n",
        "        period_id = extract_date_from_filename(filename)\n",
        "\n",
        "        try:\n",
        "            with open(file_path, 'rb') as f:\n",
        "                model = pickle.load(f)\n",
        "\n",
        "            # --- データの抽出ロジック (statsmodels / 汎用) ---\n",
        "\n",
        "            # 1. 変数名と係数の取得\n",
        "            variables = []\n",
        "            coeffs = []\n",
        "            variances = []\n",
        "\n",
        "            # パターンA: statsmodels (paramsがSeriesで変数名を持っている)\n",
        "            if hasattr(model, 'params') and isinstance(model.params, pd.Series):\n",
        "                variables = model.params.index.tolist()\n",
        "                coeffs = model.params.values\n",
        "\n",
        "                # 分散の取得 (bse^2 または cov_paramsの対角成分)\n",
        "                if hasattr(model, 'bse'):\n",
        "                    # bseは標準誤差なので2乗して分散にする\n",
        "                    variances = model.bse.values ** 2\n",
        "                elif hasattr(model, 'cov_params'):\n",
        "                    variances = np.diag(model.cov_params())\n",
        "                else:\n",
        "                    variances = [np.nan] * len(variables)\n",
        "\n",
        "            # パターンB: sklearn等 (coef_がarray, feature_namesがある場合など)\n",
        "            elif hasattr(model, 'coef_'):\n",
        "                coeffs = model.coef_\n",
        "                # 変数名 (持っていない場合は連番)\n",
        "                if hasattr(model, 'feature_names_in_'):\n",
        "                    variables = model.feature_names_in_\n",
        "                else:\n",
        "                    variables = [f'var_{i}' for i in range(len(coeffs))]\n",
        "\n",
        "                variances = [np.nan] * len(variables) # sklearnは分散を直接持たないことが多い\n",
        "\n",
        "            # パターンC: 辞書型などで保存されている場合 (カスタム)\n",
        "            elif isinstance(model, dict):\n",
        "                # 'weights', 'beta', 'params' などのキーを探す簡易ロジック\n",
        "                for key in ['params', 'weights', 'beta', 'coef']:\n",
        "                    if key in model:\n",
        "                        # ここは辞書の構造次第なので簡易的な対応です\n",
        "                        if isinstance(model[key], dict): # {var: val}形式\n",
        "                            variables = list(model[key].keys())\n",
        "                            coeffs = list(model[key].values())\n",
        "                        else: # リスト形式\n",
        "                            coeffs = model[key]\n",
        "                            variables = [f'var_{i}' for i in range(len(coeffs))]\n",
        "                        break\n",
        "                variances = [np.nan] * len(variables)\n",
        "\n",
        "            else:\n",
        "                print(f\"Warning: Could not extract data from {filename} (Unknown format)\")\n",
        "                continue\n",
        "\n",
        "            # リストに追加 (Long Format)\n",
        "            for var, coef, var_val in zip(variables, coeffs, variances):\n",
        "                all_records.append({\n",
        "                    'Period': period_id,   # 日付/識別子\n",
        "                    'Variable': var,       # 変数名\n",
        "                    'Coefficient': coef,   # 推定量 β\n",
        "                    'Variance': var_val,   # 分散\n",
        "                    'SourceFile': filename\n",
        "                })\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading {filename}: {e}\")\n",
        "\n",
        "    # データフレーム作成\n",
        "    df = pd.DataFrame(all_records)\n",
        "    return df\n",
        "\n",
        "# ==========================================\n",
        "# 3. 可視化とCSV出力\n",
        "# ==========================================\n",
        "\n",
        "def export_and_visualize(df, output_folder=\"output_results\"):\n",
        "    \"\"\"\n",
        "    データフレームを受け取り、CSV保存とグラフ描画を行う\n",
        "    \"\"\"\n",
        "    if df.empty:\n",
        "        print(\"Dataframe is empty. Nothing to export.\")\n",
        "        return\n",
        "\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # ---------------------------------------\n",
        "    # 1. CSV出力\n",
        "    # ---------------------------------------\n",
        "\n",
        "    # (A) Long Format (データベース保存用などに適した形式: 期間, 変数, 値)\n",
        "    long_csv_path = os.path.join(output_folder, \"model_params_long.csv\")\n",
        "    df.to_csv(long_csv_path, index=False)\n",
        "    print(f\"Saved Long format CSV: {long_csv_path}\")\n",
        "\n",
        "    # (B) Wide Format (ピボット形式: 横軸に期間、縦軸に変数、値は係数)\n",
        "    # Excelで見やすい形式\n",
        "    try:\n",
        "        # 係数 (Coefficient) の一覧\n",
        "        df_coef = df.pivot(index='Period', columns='Variable', values='Coefficient')\n",
        "        coef_csv_path = os.path.join(output_folder, \"model_coefficients_pivot.csv\")\n",
        "        df_coef.to_csv(coef_csv_path)\n",
        "        print(f\"Saved Coefficients Pivot CSV: {coef_csv_path}\")\n",
        "\n",
        "        # 分散 (Variance) の一覧\n",
        "        df_var = df.pivot(index='Period', columns='Variable', values='Variance')\n",
        "        var_csv_path = os.path.join(output_folder, \"model_variances_pivot.csv\")\n",
        "        df_var.to_csv(var_csv_path)\n",
        "        print(f\"Saved Variances Pivot CSV: {var_csv_path}\")\n",
        "\n",
        "    except ValueError as e:\n",
        "        print(f\"Pivot Error: {e} (Possibly duplicate entries for same period/variable)\")\n",
        "\n",
        "    # ---------------------------------------\n",
        "    # 2. 可視化 (時系列プロット)\n",
        "    # ---------------------------------------\n",
        "    # 日本語フォント設定 (必要に応じてコメントアウトを外してパスを指定してください)\n",
        "    # plt.rcParams['font.family'] = 'MS Gothic'\n",
        "\n",
        "    sns.set_theme(style=\"whitegrid\")\n",
        "\n",
        "    # (A) 係数の推移プロット\n",
        "    plt.figure(figsize=(14, 7))\n",
        "    sns.lineplot(data=df, x='Period', y='Coefficient', hue='Variable', marker='o')\n",
        "    plt.title('Time Series of Coefficients (Beta)')\n",
        "    plt.xlabel('Period (Date)')\n",
        "    plt.ylabel('Coefficient Value')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.legend(bbox_to_anchor=(1.01, 1), loc='upper left', borderaxespad=0.)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(output_folder, \"plot_coefficients.png\"))\n",
        "    plt.close() # メモリ解放\n",
        "\n",
        "    # (B) 分散の推移プロット\n",
        "    plt.figure(figsize=(14, 7))\n",
        "    sns.lineplot(data=df, x='Period', y='Variance', hue='Variable', linestyle='--', marker='x')\n",
        "    plt.title('Time Series of Estimation Variance')\n",
        "    plt.xlabel('Period (Date)')\n",
        "    plt.ylabel('Variance')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.legend(bbox_to_anchor=(1.01, 1), loc='upper left', borderaxespad=0.)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(output_folder, \"plot_variances.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    print(f\"Plots saved in '{output_folder}'\")\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# メイン実行ブロック\n",
        "# ==========================================\n",
        "if __name__ == \"__main__\":\n",
        "    # ---------------------------------------------------------\n",
        "    # 設定: ここを実際の環境に合わせて変更してください\n",
        "    # ---------------------------------------------------------\n",
        "\n",
        "    # モデルの入っているフォルダパス\n",
        "    MODELS_DIR = \"models_folder\"\n",
        "\n",
        "    # 出力先フォルダ\n",
        "    OUTPUT_DIR = \"analysis_results\"\n",
        "\n",
        "    # ---------------------------------------------------------\n",
        "    # 実行処理\n",
        "    # ---------------------------------------------------------\n",
        "\n",
        "    # 学習部分（ダミーデータ生成）はコメントアウト済み\n",
        "    # generate_mock_data(MODELS_DIR)\n",
        "\n",
        "    print(f\"Processing models in: {MODELS_DIR}\")\n",
        "\n",
        "    # 1. 読み込みと整形\n",
        "    df_results = load_and_process_models(MODELS_DIR)\n",
        "\n",
        "    if not df_results.empty:\n",
        "        # 2. CSV出力と可視化\n",
        "        export_and_visualize(df_results, OUTPUT_DIR)\n",
        "\n",
        "        print(\"\\nDone. Check the output folder.\")\n",
        "        print(df_results.head())\n",
        "    else:\n",
        "        print(\"No data was processed.\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "OuB4ZOEPJ2v-"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}